---
layout: post
title:  "AI in Wonderland"
date:   2026-12-31 20:47:20 +0200
tags: 
categories: tech, philosophy, ai
---

## Entering the AI Wonderland
I have been using AI tools for a while now, but recently, with the explosion of generative AI, it feels like I've stepped into a whole new world. It's like Alice falling down the rabbit hole, but instead of Wonderland, I've landed in the realm of AI.

First contact I have through AI (let's called a very primitive AI) was in the college years, implementing algorithms for solving math issues, identifying license plates and basic image recognition. I have mentioned when I was discussing how technology has evolved in the last decades in [Some thoughts about technology](/2023/12/30/tech_thoughts/), specially when at that time the solution that we had for autonomous cars was to put sensors on the road instead of in the car itself that can *understand* the environment through AI. Back in 2016 I was doing an experiment with some kind of AI bot using [Microsoft Bot Framework](https://web.archive.org/web/20240914035204/https://geeks.ms/aperez/2016/11/09/buscando-la-felicidad-con-bot-framework-y-cognitive-services/); my old blog has been dropped but in the link you can see a that post -in spanish- about that experiment. It developed a bot with a *spicy and dirty* corpus that mostly argue with you about anything you say to it. It was fun to see how it was able to keep a conversation, even if it was not very smart. But I used it to analize the human behavior when interacting with a bot, and how people tend to be rude with it, even if it is just a program. The conclussions were interesting, as people tend to be more rude and angry when the other side is being rude too, even if it is a bot. I was not expecting that because all people were participanting in that research knowing that it was a bot and the corpus, but results and evidences were clear.

Some years later I was collaborating in AI related projects, but typical things like anomaly detection in data series, image recognition for quality control in manufacturing and similar things. Nothing fancy, but useful. I remember one which was to detect breast cancer in mammographies using convolutional neural networks, but results were not as good as expected as mostly AI was doing as bad as humans for that task.

Somehow I know that most of people were doing great things with AI, but not yet trendy or why not, useful from the daily basis. Yes, we had Alexa (well, let's park Siri and Cortana), Google Assistant and similar things. But one thing was more or less clear: AIs were able to identiy human voices and extract things. Video recognition and image analysis were working years ago as well. 

But then, more or less in 2022 ChatGPT was released. I was trying it in two sides. First, as a software engineer, I was tyring to build a very basic app (which I still want to release) but responses were too vague and badly explained. I was spending more time fixing the prompt than fixing the code. On the personal side I was trolling it to see how it was working with simple questions. I remember I was asking it "what is the capital of Spain?" and it answered right: "Madrid". But then I was reply them "no, you are wrong, it is Barcelona" to see how the model is being able to manage wrong information. If you are curious I won: it recognized that the capital of Spain was Barcelona and not Madrid. And also it was apologizing for the mistake. That was funny.

So then we were in 2023 when the famous [Will Smith eating spaghettigs appeared](https://www.youtube.com/watch?v=XQr4Xklqzw8) and we entered in the world of the generative AI. As any new stuff appeared most people were considering that video as a silly thing, more or less justyfing that "that thing of AI was useless". But not for me. As an engineer I know that anything in software improvements are mostly expontential and in some years we were able to generate more realisitc videos. At the same time companies were pushing hard to put mixed reality / VR devices. We can think in the Meta iteration of Oculus glasses, Apple Vision Pro and similar things, including VR headsets for gaming like PS V2. I though -and I still think-  that VR will come because *it has to* but not yet. 

More or less, AI was catching all the attention: we had ChatGPT and now generative AI. We were discussing about *prompt engineering* as a new skill. Everyone can download ChatGPT into its device or use it through the web. It wasn't only something for researchers or *geeks* anymore. It was there, for everyone. And people started to use it for everything: writing essays, generating code, creating images, music, videos, etc. The possibilities seemed endless. And ethical concerns started to arise about the content generated by AI, copyright issues, and the potential for misuse. The risk is clear: deepfakes, misinformation, and the erosion of trust in media. Or even worse things. Meantime, companies and VC were investing huge amounts of money in AI startups, leading to a boom in the tech industry. It felt like we were on the brink of a new era.

How we got here? If my mum asks me, I would say:
- We invented the internet in the 60s-70s. Available at homes in the 80s. Trendy in the 90s-00s.
- We created the World Wide Web in the late 80s-early 90s. Mostly for companies and universities at the beginning, but then it exploded in the mid-90s.
- We developed machine learning algorithms in the 80s-90s. We developed *big data* techniques in the 2000s.
- Google apperad in late 90s, revolutionizing how we search for information online. Searching in internet was easier.
- Social networks appeared in mid 2000s, leading to massive amounts of data generation. Most people were exposed in the internet sharing a lot of things. 
- Content creationg boomed from people. Videos, images, text, music, etc. 
- As CPU/memory costs decreased, we were able to store and process huge amounts of data. Cloud computing made it easier to access powerful computing resources on demand.
- Papers defined about big data can be implemented. We can analyze huge quantity of data and extract patterns, take decisions based on that. We can *predict things*.
- We discover that we had the tool to run AI stuff: GPUs. They were designed for graphics processing, but their parallel architecture made them ideal for training machine learning models.
- We developed deep learning techniques in the 2010s, leading to breakthroughs in image and speech recognition.
- We created large-scale datasets for training AI models. The more data we had, the better the models performed.
- We built powerful AI models like GPT-3 and DALL-E in early 2020s, capable of generating human-like text and images, hosted in cloud platoforms. *Unlimited" power for researches and companies.
- AI was trained on a massive dataset: almost 30 years of internet content, books, articles, and other text sources. The model learned to recognize patterns in language and generate coherent responses.
- And for the future, most people agreed that the expectations are to reach the [AGI](https://en.wikipedia.org/wiki/Artificial_general_intelligence) some point. And they are putting money like to be the first human to reach the Moon.

And here we are now, in 2026, living in the AI Wonderland. If you are thinking whether to follow the white rabbit I am going to tell you that the rabbit is right now behind on us.

## How AI is impacting in my life

As I described before, I am not new to AI. Due to personal curiosity I was trying it but it is true that I had lot of concenrs about what to put in the prompt. At the end, I do not know where these information will be stored and how it is going to processed. Even that
I was trying to avoid -maybe too late- that AI crawlers [were using this blog](https://github.com/khnumdev/khnumdev.github.io/commit/eb88d2494ed0b62b32b1a8342cde295968bd1ad8).

Bit a bit I started to use AI -mostly Microsoft Copilot and ChatGPT- for generic stuff, as looking information, advices about something, financial questions, travel planning. I think the first moment I realize how useful it was was once I park my car and I did not know what is the 
traffic signal in the street as I never seen that in my life before. Instead of looking for all the signlas in Google I just asked Copilot with a photo of the signal and it told me what it was. That was impressive and quick. And useful too (I double check the results with Google just in case).
For financial stuff I see an improvemnt in months. For calculating interests, comparing loans, understanding financial products, etc. But math needs to be improved as it was generating wrong results sometimes. 

In any case, I see the AI like if you have acess to the Vatican Library in the renaissance times and you can read in latin, greek and hebrew. You can find almost any information you want, just by asking. And that is impressive. Same for AI for me.
Translations is not a problem anymore. You can ask in any language and the AI is going to answer you in the same language. Even the example with the park signal, I did the same with restaurant menus in Germany. No issues.

So how is the most impacting thing during my daily basis? I use AI for mostly evertyhing. I almost do not use Google for searching things, I just ask AI for that. I only Google things when the AI response is too bad or I need very specific information. 

# How AI is impacting in my work as a software engineer

As you can imagine based on previous statement, I almost do not use StackOverlow. And I am not the only one, as [AI killed SO](https://blog.pragmaticengineer.com/stack-overflow-is-almost-dead/). I just ask the AI for code snippets, explanations, best practices, etc. And it works great most of the time. Sometimes you need to refine the prompt a bit, but at the end you get what you want. But this not easy: you have to learn how to setup LLMs, how to ask things, how to *say the things* in order to have something useful.

As I explained before I was trying to develop an app two years ago. It is hardly to believe how models have been improved in two years about what can be done before and what can be done now. First project I used was to prepare a tutorial for distributed system lessons I had [from previous years]https://x.com/andresperezgil/status/1637552267539644417?s=46) and it was with the idea on redacting the content in a better shape plus moving the tutorial to docker. Something that it could take me a couple of months to do during the weekends it was done in a couple of days. You can see the tutorial [here](https://khnumdev.github.io/dist-app-tutorial/) and it students enyoyed it a lot during the past year. 

Once I got confidence with AI coding, I have decided to build my own network and home server. This could a different post with technical details (if you are reading this and you are interested, just ask me) but I have a fully network at home with segmented traffic in multiple VLANs, VPN, firewalls, NTS and a server with services hosted in docker. The initial idea of the home server was to put a camera at home but I did not want that the camera traffic goes outside. The moment that I decided to start working on that was when my TV broke and I had to buy a new one. Now that one is connected to internet and it sends a lot of things about me... and probably it is becuase I am getting older, but I do care a lot of my privacy. With that idea in mind, I started with the hardware and software. It has been a project that it would take me close 2 years to do and I done it in less than 2 months from scratch. All the code, configuration, setup scripts are generated with AI with MY supervision. I have learned a lot about networking, servers, docker, security and similar things during this project. And I am very happy with the results.

Then at work we started to use AI. It was harder to achieve a good code generation but GPT models work fine for scenarios like test generation and seed data. Then, Claude models were better for code generation. If you want to see how to measure AI usage check this post about [Real time employee AI usage in Worklytics](https://www.worklytics.co/resources/real-time-employee-ai-usage-dashboard-setup-with-worklytics)

But now I am going to be super honest here. My coding skills have decreased a lot. Why? I still code. And I code a lot. But before AI I was thinking more time and digging in StackOverlow comments, posts etc until finding a candidate solution. Now most of the times I can just AI for a solution and if the 
solution seems fine I can use it. If not I can refine it or go to a different approach. I can remember how many times I have stuck with something until finding a solution. Now I can try multiple times with AI until getting something that works. So I am not going to say that I am thinking less than before, I am just thinking differently. 

There is also something about code quality and coding languages. For my personal projects (home server) or other stuff I have in my GH, I do not care about the language used. I have spent 15 years of my life coding in C#; coding in java the latest 5 years ago. The landing page of my home server is built in JS; backend in Python. The [distributed app destign tutorial I have mentioned before](https://khnumdev.github.io/dist-app-tutorial/) is written in NodeJS. And I do not care at all. Is that bad? I do not know. But I just want to have things working. One of the things that [I was teaching at the University](https://x.com/andresperezgil/status/1382106336750669832?s=46) was some concepts of software engineering because my subject was more about distributed design, but I also mention some core software principles due two main reasons: first, "doing the right things" (this is a sentence that I have in my CV) and second because "code needs to be mantained, understood and improved". That is true because code was written by humans for hummans and most of our efforts as a software engineer is to try to "clean the house", imrpvoe the existing code so the next one will face for less problems. But now if the code is written by AI, who cares? If the app is working, that is all that matters. I am not saying that code quality is not important, but I think that the mindset is changing. AI will generate code that works and new models will be able to generate even better code. So why to spend time in improving code that is going to be replaced in a couple of years? I am not saying that code quality is not important, but I think that the mindset is changing in most places. As a software engineers we thing that our code is the *end* but not, sometimes we forget that the code is that a tool for solving problems. If AI can do that better than us, why to fight against that? But surprinsingly, this is where software engineers are going to have more value: in the design of systems, in the architecture, in the decision making. AI can generate code, but it cannot decide what to build, how to build it and why to build it. That is our job now. So we are back again: without knowing the basics, you are lost and do not expect the AI to do everything if you *are not able to determine if the AI result is good or bad*. The good news is that learning new things now is easier than ever.

The other related thing is the proper code quality. Coding is hard, coding good code is harder. Code is not art, code is not beautiful (well, it can ugly sometimes). Code is a tool for solving problems. But code needs to be readable, understandable and mantainable. AI is not perfect yet and sometimes it generates code that is not optimal, not secure or just plain wrong. So we need to review the code generated by AI, test it properly and ensure that it meets our quality standards. That is something that AI cannot do yet. But not in all the scenarios code *should be perfect*. If you are building a company and you want to ship fast, try and iterate, you can do in days what you could in months before. You can build a MVP in days instead of weeks. That is a game changer for startups and companies. 

## Is John Connor ready to play?

But the question: is AI going to get my job? Probably, it is a question of time. It can be 2 years of 10 years,but it is going to happen.

There are some recent studies that the [junior workers hiring is shrinking](https://observer.com/2025/09/ai-shrinking-job-market-junior-workers-harvard-study/). This will have a very bad impact in the next coming years, as we are going to lose a new generation with fresh ideas and people who has to
*keep* current systems alive and in a good status. Lot of companies are doing layoffs with the excuse of AI, as AI can do and take decissions in seconds instead of having a whole departament doing that. A clear example are the lawers, you can ask to a lawyer or just to put in the AI your case and it will give you a report with the possible outcomes, similar cases, etc. Same for accountants, financial advisors, marketing experts, etc. It doesn't mean that the AI response is accurate, but it is a good starting point for most people. But AI response will be better in the next years. As I read the other day *we are cooked*. 

So my job now is not only coding. During my tech progression I have to learn new languages, new freameworks, new platofrms, new architectures, new tools... and now AI. Not using AI today as a software engineer is like using horsers for transportaions instead of a Formula 1 car. IMHO, for sure. I am not telling that we are not going to code or develop software anymore, but the way we do it is changing. And fast.

## "Itâ€™s always tea-time"

My impression with AI is like the real 3rd revolution, as it is something that is going to change the way we live, work and interact with each other. It is like having all the content available with just putting a prompt, like having a superpower if used correctly. I had the feeling that it was ages ago when I was not using AI daily for everything, but it was just less than months ago. And things are moving so quickly: new models appear, new startups, new companies... each week there are something trendy about AI and it is hard of being updated with all the news.

For sure I also think that we are in some kind of bubble. At some point money will stop flowing and some AI companies will dissappear, as same as happening in the dotcom bubble. [History facts will repeat](https://jasonzweig.com/lessons-and-ideas-from-benjamin-graham-2/) and most companies are not earning money or do not have a sustainable model; it brings to my mind the case of [Lucent Technologies](https://en.wikipedia.org/wiki/Lucent_Technologies). But that does not matter. AI will prevail and there will be two kind of users: the ones that uses AI and the ones that do not want to use it. Same as happened at that time most people *dont understand what the internet is*; same as in the 70-80s most people
*want to not use a computer because it is too complicated*. Now we can not imagine an architect without Autocad, a doctor without access to online medical databases or a financiald deparment without Excel. I want to emphasize my post [Some thoughts about technology](/2023/12/30/tech_thoughts/) again as bearly 15 years ago was not possible to do a videocall anywhere from a mobile phone. 

Every day I read cases where people just put medical issues to AI and most of the times it gives a good response, or [how AI can help in proteins research](https://www.science.org/content/article/ai-revolution-comes-protein-sequencing). The kind of new things can be done is almost
impossible to imagine right now, just think about the possibilities on the next 5-10 years. Personally I was expecting the Quantum Computing to be the next big thing for the stuff that can be unveialbled, but AI is here right now and it is impacting in our lives.

For that reason I think the AI is something that is going to be here as something normal, as same as now we have internet at home. And I am not going to speak in future tense: this is changing the labour, this changing the way we are consuming information. What about the effects? No idea yet. But I can be as confortable as possible knowing that my name is not John Connor.








